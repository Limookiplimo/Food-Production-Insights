{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89416139",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3633b4a",
   "metadata": {},
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a94cb",
   "metadata": {},
   "source": [
    "Perform the following tasks:\n",
    "- data cleaning\n",
    "- data filtering\n",
    "- data wrangling\n",
    "- data enrichment\n",
    "- data validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad8a5a9",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45357d1a",
   "metadata": {},
   "source": [
    "After transformations, the data is analyzed using Tableau. FInd the interactive copy [here]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa35aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook environment settings\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "#ignoring timezone warning\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "\n",
    "#filter out warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf38101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages and libraries\n",
    "import pyspark\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, when, sum as spark_sum\n",
    "from pyspark.sql.types import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d4d6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"F-A-O\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b44b7bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maxToStringFields property\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", \"100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a6281e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 4) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get the dataset\n",
    "prod_data = spark\\\n",
    "            .read\\\n",
    "            .options(inferSchema=\"true\", header=\"true\")\\\n",
    "            .csv(\"Production_Crops_Livestock_E_Africa.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bebc0b",
   "metadata": {},
   "source": [
    "There are columns that do not add direct context to my analysis. I will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5a6e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "# drop flag cols\n",
    "to_drop = [col for col in prod_data.columns if col.endswith(\"F\")]\n",
    "\n",
    "# drop unnecessary cols\n",
    "to_drop1 = ['Area Code','Area Code (M49)','Item Code','Item Code (CPC)','Element','Element Code','Unit']\n",
    "\n",
    "# implement\n",
    "prod_data = (prod_data\\\n",
    "            .drop(*to_drop, *to_drop1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e218f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "#rename year cols\n",
    "renamed_cols = [col.replace('Y', '') for col in prod_data.columns]\n",
    "prod_data = prod_data.toDF(*renamed_cols)\n",
    "\n",
    "#rename other cols\n",
    "prod_data = prod_data\\\n",
    "                .withColumnRenamed(\"Area\", \"Country\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b97b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim column names\n",
    "prod_data = prod_data.select([col(name).alias(name.strip()) for name in prod_data.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0746f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt dataframe\n",
    "#convert spark to pandas df\n",
    "prod_data = ps.DataFrame(prod_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0600bd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#melt the pandas df\n",
    "keep_columns=['Country', 'Item']\n",
    "prod_data=prod_data.melt(id_vars=keep_columns, var_name='Year',value_name='Weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d84583",
   "metadata": {},
   "source": [
    "I converted the dataframe to pandas dataframe in order to melt it. I could not get along with unpivoting the dataframe with pyspark. If you know how, kindly reach out.\n",
    "Now I'll have to covert the dataframe back to spark DF for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa51110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Convert pandas dataframe to RDD \n",
    "r_dd = spark.sparkContext.parallelize(prod_data.values.tolist())\n",
    "\n",
    "#Schema for the pyspark dataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"Country\", StringType(), nullable=False),\n",
    "    StructField(\"Item\", StringType(), nullable=False),\n",
    "    StructField(\"Year\", StringType(), nullable=False),\n",
    "    StructField(\"Weight\", DoubleType(), nullable=False)\n",
    "])\n",
    "\n",
    "#create pyspark dataFrame\n",
    "prod_data = spark.createDataFrame(r_dd, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13af194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column\n",
    "prod_data = prod_data.withColumn(\"Category\",lit(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48118452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize items\n",
    "grains=['Wheat and products', 'Rice (Milled Equivalent)','Barley and products','Maize and products',\n",
    "        'Millet and products','Cereals, Other','Cereals - Excluding Beer','Rye and products','Oats',\n",
    "        'Sorghum and products','Cassava and products','Cereals n.e.c.','Wheat','Maize (corn)','Sorghum','Triticale',\n",
    "       'Fonio']\n",
    "vegetables=['Potatoes and products','Vegetables, Other','Starchy Roots','Vegetables','Sweet potatoes','Roots, Other',\n",
    "            'Onions','Plantains','Pimento','Aquatic Plants','Yams','Potatoes','Roots and Tubers, Total',\n",
    "           'Eggplants (aubergines)','Cauliflowers and broccoli','Edible roots and tubers with high starch or inulin content, n.e.c., fresh',\n",
    "           'Mushrooms and truffles','Other vegetables, fresh n.e.c.','Apricots','Roots and Tubers, Total',\n",
    "           'Tomatoes','Cucumbers and gherkins','Chillies and peppers, green (Capsicum spp. and Pimenta spp.)',\n",
    "           'Cabbages','Carrots and turnips','Cassava, fresh']\n",
    "sugars=['Sugar (Raw Equivalent)','Sweeteners, Other','Sugar Crops','Sugar & Sweeteners','Sugar non-centrifugal',\n",
    "        'Sugar beet','Sugar cane','Molasses','Raw cane or beet sugar (centrifugal only)']\n",
    "fruits=['Olives-Including Preserved','Tomatoes and products','Oranges, Mandarines','Citrus, Other','Bananas',\n",
    "        'Apples and products','Pineapples and products','Dates','Grapes and Products-Excluding Wine','Fruits, Other',\n",
    "        'Fruits - Excluding Wine','Lemons, Limes and products','Grapefruit and products','Pineapples',\n",
    "        'Plums and sloes','Watermelons','Figs','Pomelos and grapefruits','Other fruits, n.e.c.','Fruit Primary',\n",
    "       'Tangerines, mandarins, clementines','Mangoes, guavas and mangosteens','Quinces','Grapes']\n",
    "legumes=['Pulses, Other and products','Coffee and products','Cocoa Beans and products','Pulses','Beans','Peas',\n",
    "         'Soyabeans','Groundnuts-Shelled Eq','Cocoa beans','Broad beans and horse beans, green','Other beans, green',\n",
    "        '|Lentils, dry','Okra','Cashew nuts, in shell','Groundnuts, excluding shelled','Vetches','Soya beans',\n",
    "        'Broad beans and horse beans, dry']\n",
    "seeds=['Sesame seed', 'Rape and Mustardseed','Palm kernels','Sunflower seed','Cottonseed','Castor oil seeds',\n",
    "      'Rape or colza seed','Melonseed','Cotton seed']\n",
    "nuts=['Nuts and products','Almonds, in shell','Coconuts - Incl Copra','Treenuts','Coconuts, in shell']\n",
    "oils_fats=['Soyabean Oil','Groundnut Oil','Sunflowerseed Oil','Rape and Mustard Oil','Cottonseed Oil','Palm Oil',\n",
    "           'Sesameseed Oil','Olive Oil','Oilcrops Oil, Other','Oilcrops','Vegetable Oils','Oilcrops, Other',\n",
    "           'Maize Germ Oil','Coconut Oil','Palmkernel Oil','Ricebran Oil','Fish, Body Oil','Fish, Liver Oil',\n",
    "           'Animal fats','Fats, Animals, Raw','Olive oil','Rapeseed or canola oil, crude','Cheese (All Kinds)',\n",
    "           'Olives','Oil of palm kernel','Palm oil','Cattle fat, unrendered','Groundnut oil',\n",
    "          'Safflower-seed oil, crude','Pig fat, rendered','Goat fat, unrendered','Margarine and shortening']\n",
    "beverages=['Tea-Including Mate','Wine','Beer','Beverages, Alcoholic','Alcoholic Beverages','Beverages, Fermented',\n",
    "           'Coffee, green']\n",
    "spices=['Pepper','Spices, Other','Spices','Cloves','Green garlic']\n",
    "meat=['Bovine Meat','Mutton & Goat Meat','Meat, Other','Meat','Pigmeat','Game meat, fresh, chilled or frozen',\n",
    "     'Horse meat, fresh or chilled']\n",
    "sea_food=['Freshwater Fish','Fish, Seafood','Demersal Fish','Pelagic Fish','Marine Fish, Other','Crustaceans',\n",
    "          'Cephalopods','Molluscs, Other','Aquatic Animals, Others','Aquatic Products, Other',\n",
    "          'Meat, Aquatic Mammals']\n",
    "dairy=['Butter, Ghee','Cream','Milk - Excluding Butter','Infant food','Butter of cow milk','Skim Milk & Buttermilk, Dry',\n",
    "       'Buttermilk, dry','Cheese from skimmed cow milk','Skim milk of cows','Cheese from whole cow milk',\n",
    "       'Milk, Total','Raw milk of sheep']\n",
    "poultry=['Eggs','Poultry Meat','Turkeys','Chickens','Hen eggs in shell, fresh','Poultry Birds']\n",
    "other_animal_products=['Honey','Bees','Offals','Offals, Edible','Edible offals of horses and other equines,  fresh, chilled or frozen',\n",
    "                      'Raw hides and skins of sheep or lambs','Other meat n.e.c. (excluding mammals), fresh, chilled or frozen',\n",
    "                      'Edible offal of cattle, fresh, chilled or frozen','Sheep and Goats','Asses','Raw hides and skins of cattle',\n",
    "                      'Beeswax','Edible offals of camels and other camelids, fresh, chilled or frozen',\n",
    "                      'Rabbits and hares','Raw hides and skins of goats or kids','Camels','Swine / pigs']\n",
    "miscellaneous=['Stimulants','Miscellaneous']\n",
    "other_plant_products=['Flax, processed but not spun','Unmanufactured tobacco','Sisal, raw','Cotton lint, ginned','Fibre Crops, Fibre Equivalent']\n",
    "\n",
    "# Pattern matching with regex\n",
    "grains_regex = '|'.join(grains)\n",
    "vegetables_regex = '|'.join(vegetables)\n",
    "sugars_regex= '|'.join(sugars)\n",
    "fruits_regex = '|'.join(fruits)\n",
    "legumes_regex = '|'.join(legumes)\n",
    "seeds_regex = '|'.join(seeds)\n",
    "nuts_regex = '|'.join(nuts)\n",
    "oils_fats_regex = '|'.join(oils_fats)\n",
    "beverages_regex = '|'.join(beverages)\n",
    "spices_regex = '|'.join(spices)\n",
    "meat_regex = '|'.join(meat)\n",
    "sea_food_regex = '|'.join(sea_food)\n",
    "dairy_regex = '|'.join(dairy)\n",
    "poultry_regex = '|'.join(poultry)\n",
    "other_animal_products_regex = '|'.join(other_animal_products)\n",
    "miscellaneous_regex = '|'.join(miscellaneous)\n",
    "other_plant_products_regex = '|'.join(other_plant_products)\n",
    "\n",
    "# Update \"Category\" column based on the values in \"Item\" column\n",
    "prod_data = prod_data.withColumn(\"Category\",\n",
    "                                 when(col(\"Item\").rlike(grains_regex), lit(\"Grains\"))\n",
    "                                 .when(col(\"Item\").rlike(vegetables_regex), lit(\"Vegetables\"))\n",
    "                                 .when(col(\"Item\").rlike(sugars_regex), lit(\"Sugar\"))\n",
    "                                 .when(col(\"Item\").rlike(fruits_regex), lit(\"Fruits\"))\n",
    "                                 .when(col(\"Item\").rlike(legumes_regex), lit(\"Legumes\"))\n",
    "                                 .when(col(\"Item\").rlike(seeds_regex), lit(\"Seeds\"))\n",
    "                                 .when(col(\"Item\").rlike(nuts_regex), lit(\"Nuts\"))\n",
    "                                 .when(col(\"Item\").rlike(oils_fats_regex), lit(\"Oil_Fats\"))\n",
    "                                 .when(col(\"Item\").rlike(beverages_regex), lit(\"Beverages\"))\n",
    "                                 .when(col(\"Item\").rlike(spices_regex), lit(\"Spices\"))\n",
    "                                 .when(col(\"Item\").rlike(meat_regex), lit(\"Meat\"))\n",
    "                                 .when(col(\"Item\").rlike(sea_food_regex), lit(\"Sea_Food\"))\n",
    "                                 .when(col(\"Item\").rlike(dairy_regex), lit(\"Dairy\"))\n",
    "                                 .when(col(\"Item\").rlike(poultry_regex), lit(\"Poultry\"))\n",
    "                                 .when(col(\"Item\").rlike(other_animal_products_regex), lit(\"Other_Animal_Products\"))\n",
    "                                 .when(col(\"Item\").rlike(miscellaneous_regex), lit(\"Miscellaneous\"))\n",
    "                                 .when(col(\"Item\").rlike(other_plant_products_regex), lit(\"Other_Plant_Products\"))\n",
    "                                 .otherwise(col(\"Category\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907ccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "null_counts = prod_data\\\n",
    "                .select([spark_sum(col(column).isNull().cast(\"integer\")).alias(column) for column in prod_data.columns])\n",
    "null_counts_dict = null_counts.first().asDict()\n",
    "for column, count in null_counts_dict.items():\n",
    "    print(f\"Column '{column}': {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86282833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/05 22:31:07 WARN TaskSetManager: Stage 9 contains a task of very large size (50026 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save the DF as CSV\n",
    "prod_data.coalesce(1).write.csv(\"FAO.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6434bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
