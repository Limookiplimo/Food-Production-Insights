{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf38101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages and libraries\n",
    "import pyspark\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import *\n",
    "import warnings\n",
    "\n",
    "#filter out warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d4d6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize spark session\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a6281e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset\n",
    "prod_data = (spark\\\n",
    "            .read\\\n",
    "            spark.conf.set(\"spark.default.parallelism\", newParallelismValue)\n",
    "\n",
    "            .csv(\"Production_Crops_Livestock_E_Africa.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0993ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure output partitions\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bebc0b",
   "metadata": {},
   "source": [
    "There are columns that do not add direct context to my analysis. I will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5a6e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "\n",
    "# drop flag cols\n",
    "to_drop = [col for col in prod_data.columns if col.endswith(\"F\")]\n",
    "\n",
    "# drop unnecessary cols\n",
    "to_drop1 = ['Area Code','Area Code (M49)','Item Code','Item Code (CPC)','Element Code','Unit']\n",
    "\n",
    "# implement\n",
    "prod_data = (prod_data\\\n",
    "            .drop(*to_drop, *to_drop1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e218f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "#rename year cols\n",
    "renamed_cols = [col.replace('Y', '') for col in prod_data.columns]\n",
    "prod_data = prod_data.toDF(*renamed_cols)\n",
    "\n",
    "#rename other cols\n",
    "prod_data = prod_data\\\n",
    "                .withColumnRenamed(\"Area\", \"Country\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b97b6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Element: string (nullable = true)\n",
      " |-- 1961: double (nullable = true)\n",
      " |-- 1962: double (nullable = true)\n",
      " |-- 1963: double (nullable = true)\n",
      " |-- 1964: double (nullable = true)\n",
      " |-- 1965: double (nullable = true)\n",
      " |-- 1966: double (nullable = true)\n",
      " |-- 1967: double (nullable = true)\n",
      " |-- 1968: double (nullable = true)\n",
      " |-- 1969: double (nullable = true)\n",
      " |-- 1970: double (nullable = true)\n",
      " |-- 1971: double (nullable = true)\n",
      " |-- 1972: double (nullable = true)\n",
      " |-- 1973: double (nullable = true)\n",
      " |-- 1974: double (nullable = true)\n",
      " |-- 1975: double (nullable = true)\n",
      " |-- 1976: double (nullable = true)\n",
      " |-- 1977: double (nullable = true)\n",
      " |-- 1978: double (nullable = true)\n",
      " |-- 1979: double (nullable = true)\n",
      " |-- 1980: double (nullable = true)\n",
      " |-- 1981: double (nullable = true)\n",
      " |-- 1982: double (nullable = true)\n",
      " |-- 1983: double (nullable = true)\n",
      " |-- 1984: double (nullable = true)\n",
      " |-- 1985: double (nullable = true)\n",
      " |-- 1986: double (nullable = true)\n",
      " |-- 1987: double (nullable = true)\n",
      " |-- 1988: double (nullable = true)\n",
      " |-- 1989: double (nullable = true)\n",
      " |-- 1990: double (nullable = true)\n",
      " |-- 1991: double (nullable = true)\n",
      " |-- 1992: double (nullable = true)\n",
      " |-- 1993: double (nullable = true)\n",
      " |-- 1994: double (nullable = true)\n",
      " |-- 1995: double (nullable = true)\n",
      " |-- 1996: double (nullable = true)\n",
      " |-- 1997: double (nullable = true)\n",
      " |-- 1998: double (nullable = true)\n",
      " |-- 1999: double (nullable = true)\n",
      " |-- 2000: double (nullable = true)\n",
      " |-- 2001: double (nullable = true)\n",
      " |-- 2002: double (nullable = true)\n",
      " |-- 2003: double (nullable = true)\n",
      " |-- 2004: double (nullable = true)\n",
      " |-- 2005: double (nullable = true)\n",
      " |-- 2006: double (nullable = true)\n",
      " |-- 2007: double (nullable = true)\n",
      " |-- 2008: double (nullable = true)\n",
      " |-- 2009: double (nullable = true)\n",
      " |-- 2010: double (nullable = true)\n",
      " |-- 2011: double (nullable = true)\n",
      " |-- 2012: double (nullable = true)\n",
      " |-- 2013: double (nullable = true)\n",
      " |-- 2014: double (nullable = true)\n",
      " |-- 2015: double (nullable = true)\n",
      " |-- 2016: double (nullable = true)\n",
      " |-- 2017: double (nullable = true)\n",
      " |-- 2018: double (nullable = true)\n",
      " |-- 2019: double (nullable = true)\n",
      " |-- 2020: double (nullable = true)\n",
      " |-- 2021: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trim column names\n",
    "prod_data = prod_data.select([col(name).alias(name.strip()) for name in prod_data.columns])\n",
    "prod_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0746f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt dataframe\n",
    "#convert spark to pandas df\n",
    "prod_data = ps.DataFrame(prod_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0600bd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:===================>                                       (1 + 2) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Item</th>\n",
       "      <th>Element</th>\n",
       "      <th>Year</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Almonds, in shell</td>\n",
       "      <td>Area harvested</td>\n",
       "      <td>Year</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Almonds, in shell</td>\n",
       "      <td>Area harvested</td>\n",
       "      <td>Weight</td>\n",
       "      <td>13300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Almonds, in shell</td>\n",
       "      <td>Area harvested</td>\n",
       "      <td>Year</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Almonds, in shell</td>\n",
       "      <td>Area harvested</td>\n",
       "      <td>Weight</td>\n",
       "      <td>13300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Almonds, in shell</td>\n",
       "      <td>Area harvested</td>\n",
       "      <td>Year</td>\n",
       "      <td>1963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country               Item         Element    Year   Weight\n",
       "0  Algeria  Almonds, in shell  Area harvested    Year     1961\n",
       "1  Algeria  Almonds, in shell  Area harvested  Weight  13300.0\n",
       "2  Algeria  Almonds, in shell  Area harvested    Year     1962\n",
       "3  Algeria  Almonds, in shell  Area harvested  Weight  13300.0\n",
       "4  Algeria  Almonds, in shell  Area harvested    Year     1963"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#melt the pandas df\n",
    "keep_columns=['Country', 'Item', 'Element']\n",
    "prod_data=prod_data.melt(id_vars=keep_columns, var_name='Year',value_name='Weight')\n",
    "prod_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d84583",
   "metadata": {},
   "source": [
    "I converted the dataframe to pandas dataframe in order to melt it. I could not get along with unpivoting the dataframe with pyspark. If you know how, kindly reach out.\n",
    "Now I'll have to covert the dataframe back to spark DF for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38d354fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.pandas.frame.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prod_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3aa51110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas dataframe to RDD \n",
    "rdd = spark.sparkContext.parallelize(prod_data.values.tolist())\n",
    "\n",
    "#Schema for the pyspark dataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"Country\", StringType(), nullable=False),\n",
    "    StructField(\"Item\", StringType(), nullable=False),\n",
    "    StructField(\"Element\", StringType(), nullable=False),\n",
    "    StructField(\"Year\", StringType(), nullable=False),\n",
    "    StructField(\"Weight\", DoubleType(), nullable=False)\n",
    "])\n",
    "\n",
    "#create pyspark dataFrame\n",
    "df1 = spark.createDataFrame(rdd, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7fedc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af194a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68131ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48118452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907ccb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86282833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6434bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c6a428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22babee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f5aacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2023151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meditation HQ\n",
    "\n",
    " # .withColumnRenamed(\"year\", trim(col(\"year\")).alias(\"year\"))\n",
    "# keep_columns = ['Country', 'Item', 'Element']\n",
    "# other_columns = [col(column) for column in prod_data.columns if column not in keep_columns]\n",
    "# other_df = prod_data.select(*other_columns)\n",
    "\n",
    "\n",
    "# other_df.printSchema()\n",
    "# # Assuming you have a DataFrame named 'df' with the year columns and other columns\n",
    "# keep_columns = ['Area', 'Item', 'Element']\n",
    "# year_columns = [col for col in prod_data.columns if col not in keep_columns]\n",
    "\n",
    "\n",
    "# # Melt the year columns\n",
    "# prod_data = prod_data.select(keep_columns + [\n",
    "#     explode(\n",
    "#         [\n",
    "#             (lit(col).alias('year'), col)\n",
    "#             for col in year_columns\n",
    "#         ]\n",
    "#     ).alias('melted')\n",
    "# ]).select(keep_columns + [\n",
    "#     col('melted.year'),\n",
    "#     col('melted.weight')\n",
    "# ])\n",
    "\n",
    "\n",
    "# prod_data.show()\n",
    "\n",
    "# melted_df = renamed_df.selectExpr(\"stack(61, \" + \", \".join([f\"'{col}', {col}\" for col in renamed_df.columns]) + \") as (year, weight)\")\n",
    "\n",
    "# from pyspark.sql.functions import expr\n",
    "\n",
    "# melted_df = other_df.selectExpr(\"posexplode(array(*)) as (year, weight)\").select(\"year\", \"weight\")\n",
    "\n",
    "# melted_df.show()\n",
    "\n",
    "\n",
    "# cols = other_df.columns\n",
    "# other_df = other_df.selectExpr(\"stack({},{})\".format(len(cols), ','.join((\"'{}'\".format(i) for i in cols))))\n",
    "# other_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfef26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
